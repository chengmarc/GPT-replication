### Repository Summary ###
- Task: Natural Language Processing
- Model Type: Generative Pre-training Transformer
- Total number of parameters: 162,419,712
- Total size of the model: 619.58 MB

### Theoretic References ###

[1] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever.

    Language Models are Unsupervised Multitask Learners
    https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf

[2] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, 
    Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin.

    Attention Is All You Need
    https://arxiv.org/pdf/1706.03762
    
[3] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean.

    Distributed Representations of Words and Phrases and their Compositionality
    https://arxiv.org/abs/1310.4546
    
[4] Y. Lecun, L. Bottou, Y. Bengio, P. Haffner.

    Gradient-based learning applied to document recognition
    http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf
    
[5] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov.

    Dropout: A Simple Way to Prevent Neural Networks from Overfitting
    https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf
    
[6] Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton.

    Layer Normalization
    https://arxiv.org/pdf/1607.06450
    
[7] Dan Hendrycks, Kevin Gimpel.

    Gaussian Error Linear Units (GELUs)
    https://arxiv.org/pdf/1606.08415
    
[8] Abien Fred Agarap.

    Deep Learning using Rectified Linear Units (ReLU)
    https://arxiv.org/abs/1803.08375
    
[9] Philip Gage.

    A new algorithm for data compression (Byte Pair Encoding)
    https://dl.acm.org/doi/abs/10.5555/177910.177914

### Dataset References ###
[10] William Shakespeare - Project Gutenberg

    The Complete Works of William Shakespeare
    https://www.gutenberg.org/ebooks/100
    
### Code Reference ### 
[11] Sebastian Raschka 

    Build a Large Language Model (From Scratch)
    https://github.com/rasbt/LLMs-from-scratch
